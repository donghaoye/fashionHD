from __future__ import print_function, division
import util.io as io
import scipy.io
import numpy as np
import imageio
import tqdm
import cv2
import os
from misc import pose_util

####################################
# global config
####################################
num_sample = 64


####################################
# PatchMatch
####################################
# These functions are used to generate image descriptor for patchmatching
# The code which applys patchmatch and compute image reconstruction is at "patch_matching_and_flow/patchmatch-2.1/script_patchmatch_discriptor.m"
def create_image_info():
    '''
    create a .mat file containing:
    - id_1
    - id_2
    - image_1
    - image_2
    - image_gen (generated by PoseTranfer_x)
    '''
    image_dir = '/data2/ynli/datasets/DF_Pose/Img/img_df/'
    model_id = 'PoseTransfer_7.5'
    image_gen_dir = '/data2/ynli/Fashion/fashionHD/checkpoints/%s/test/' % model_id

    pair_indices = io.load_json('datasets/DF_Pose/Label/pair_split.json')['test'][0:num_sample]
    pose_label = io.load_data('datasets/DF_Pose/Label/pose_label.pkl')
    id_1 = [p[0] for p in pair_indices]
    id_2 = [p[1] for p in pair_indices]
    image_1 = []
    image_2 = []
    image_gen = []
    scale_2over1 = []

    for i in range(num_sample):
        image_1.append(image_dir + id_1[i] + '.jpg')
        image_2.append(image_dir + id_2[i] + '.jpg')
        image_gen.append(image_gen_dir + '%s_%s.jpg'%(id_1[i], id_2[i]))
        pose_1 = np.array(pose_label[id_1[i]])
        pose_2 = np.array(pose_label[id_2[i]])
        scale_2over1.append(pose_util.relative_scale_from_pose(pose_2, pose_1))
    
    image_info = {
        'id_1': id_1,
        'id_2': id_2,
        'image_1': image_1,
        'image_2': image_2,
        'image_gen': image_gen,
        'model_id': model_id,
        'scale_2over1': scale_2over1
    }
    data_dict = {k:np.array(v, dtype=np.object) for k,v in image_info.iteritems()}
    io.save_json(image_info, 'temp/patch_matching/label/image_info.json') # for other functions in this script
    scipy.io.matlab.savemat('temp/patch_matching/label/image_info.mat', data_dict) # for PatchMatch matlab tools and other matlab implementions


def _read_seg(fn, n_class=8):
    seg_label = imageio.imread(fn).astype(np.int)
    seg = [(seg_label == i) for i in range(n_class)]
    seg = np.stack(seg, axis=2).astype(np.float32)
    if n_class==8:
        seg[...,3] = seg[...,3]+seg[...,7]
        seg = seg[...,0:7]
    return seg

def create_descriptor_seg():
    model_id = 'PoseTransfer_7.5'
    seg_dir = 'datasets/DF_Pose/Img/seg-lip_df/'
    seg_dir_gen = '/data2/ynli/Fashion/fashionHD/checkpoints/%s/test_seg/' % model_id
    
    image_info = io.load_json('temp/patch_matching/label/image_info.json')
    id_1 = image_info['id_1']
    id_2 = image_info['id_2']

    desc_1 = []
    desc_2 = []
    desc_gen = []
    for i in range(num_sample):
        fn_1 = seg_dir + id_1[i] + '.bmp'
        fn_2 = seg_dir + id_2[i] + '.bmp'
        fn_gen = seg_dir_gen + '%s_%s.bmp' % (id_1[i], id_2[i])
        desc_1.append(_read_seg(fn_1))
        desc_2.append(_read_seg(fn_2))
        desc_gen.append(_read_seg(fn_gen))

    data_dict_gt = {
        'desc_1': np.stack(desc_1),
        'desc_2': np.stack(desc_2),
        'name': 'gt_seg'
    }
    data_dict_gen = {
        'desc_1': np.stack(desc_1),
        'desc_2': np.stack(desc_gen),
        'name': 'gen_seg'
    }

    scipy.io.matlab.savemat('temp/patch_matching/descriptor/desc_gt_seg.mat', data_dict_gt)
    scipy.io.matlab.savemat('temp/patch_matching/descriptor/desc_gen_seg.mat', data_dict_gen)

def create_descriptor_rgb():
    image_info = io.load_json('temp/patch_matching/label/image_info.json')
    desc_1 = []
    desc_2 = []
    desc_gen = []

    for fn_1, fn_2, fn_gen in zip(image_info['image_1'], image_info['image_2'], image_info['image_gen']):
        desc_1.append(imageio.imread(fn_1))
        desc_2.append(imageio.imread(fn_2))
        desc_gen.append(imageio.imread(fn_gen))
    
    desc_1 = np.stack(desc_1).astype(np.float32)/127.5 - 1.
    desc_2 = np.stack(desc_2).astype(np.float32)/127.5 - 1.
    desc_gen = np.stack(desc_gen).astype(np.float32)/127.5 -1.

    data_dict_gt = {
        'desc_1': desc_1,
        'desc_2': desc_2,
        'name': 'gt_rgb'
    }
    data_dict_gen = {
        'desc_1': desc_1,
        'desc_2': desc_gen,
        'name': 'gen_rgb'
    }

    scipy.io.matlab.savemat('temp/patch_matching/descriptor/desc_gt_rgb.mat', data_dict_gt)
    scipy.io.matlab.savemat('temp/patch_matching/descriptor/desc_gen_rgb.mat', data_dict_gen)

def create_descriptor_vgg():
    import torch
    import torch.nn.functional as F
    from models.networks import VGGLoss_v2
    vgg = VGGLoss_v2(gpu_ids=[0])
    image_info = io.load_json('temp/patch_matching/label/image_info.json')
    
    images_1 = np.stack([imageio.imread(fn) for fn in image_info['image_1']]).astype(np.float32)/127.5 -1.
    images_2 = np.stack([imageio.imread(fn) for fn in image_info['image_2']]).astype(np.float32)/127.5 -1.
    images_gen = np.stack([imageio.imread(fn) for fn in image_info['image_gen']]).astype(np.float32)/127.5 -1.

    desc_dict = {}
    batch_size = 16
    for idx in ['1', '2', 'gen']:
        print('compute feature for images_%s'%idx)
        images = np.stack([imageio.imread(fn) for fn in image_info['image_%s'%idx]]).astype(np.float32)/127.5 -1.
        n, h, w = images.shape[0:3]
        # compute features
        feat_pyramid = []
        for s in range(0, n, batch_size):
            e = s + batch_size
            print('>> image %d-%d' % (s, e))
            batch = torch.Tensor(images[s:e].transpose(0,3,1,2)).cuda()
            with torch.no_grad():
                feat_pyramid_b = vgg.compute_feature(vgg.normalize(batch)) # [relu1, relu2, relu3, relu4, relu5]
            # # upscale
            # feat_pyramid_b = [F.upsample(feat, (h, w), mode='bilinear') for feat in feat_pyramid_b]
            # normalization
            feat_pyramid_b = [(feat / (feat.norm(dim=1, keepdim=True)+1e-8)).cpu() for feat in feat_pyramid_b]
            
            if feat_pyramid:
                for i, feat_b in enumerate(feat_pyramid_b):
                    feat_pyramid[i] = torch.cat((feat_pyramid[i], feat_b), dim=0)
            else:
                feat_pyramid = feat_pyramid_b

        for l, feat in enumerate(feat_pyramid):
            desc_dict['desc_%s_level_%d' % (idx, l+1)] = feat.numpy().transpose(0, 2, 3, 1)

    for l in range(1, 1+len(feat_pyramid)):
        print('saving descriptor %d/%d' % (l, len(feat_pyramid)))
        data_dict_gt = {
            'desc_1': desc_dict['desc_1_level_%d'%l],
            'desc_2': desc_dict['desc_2_level_%d'%l],
            'name': 'gt_vgg_h%d'%l
        }
        data_dict_gen = {
            'desc_1': desc_dict['desc_1_level_%d'%l],
            'desc_2': desc_dict['desc_gen_level_%d'%l],
            'name': 'gen_vgg_h%d'%l
        }
        scipy.io.matlab.savemat('temp/patch_matching/descriptor/desc_gt_vgg_h%d.mat'%l, data_dict_gt)
        scipy.io.matlab.savemat('temp/patch_matching/descriptor/desc_gen_vgg_h%d.mat'%l, data_dict_gen)


def create_descriptor_segment_guided_rgb():
    '''This function is deprecated. Segment guide is applied in expand_descriptor_by_seg.m'''
    model_id = 'PoseTransfer_7.5'
    image_info = io.load_json('temp/patch_matching/label/image_info.json')
    seg_dir = 'datasets/DF_Pose/Img/seg-lip_df/'
    seg_dir_gen = '/data2/ynli/Fashion/fashionHD/checkpoints/%s/test_seg/' % model_id
    desc_rgb = scipy.io.loadmat('temp/patch_matching/descriptor/desc_gt_rgb.mat')
    desc_rgb_gen = scipy.io.loadmat('temp/patch_matching/descriptor/desc_gen_rgb.mat')

    desc_rgb_all = {
        '1': desc_rgb['desc_1'],
        '2': desc_rgb['desc_2'],
        'gen': desc_rgb_gen['desc_2'],
    }

    desc = {}
    for subset in ['1', '2', 'gen']:
        desc[subset] = []
        for i in range(num_sample):
            d_rgb = desc_rgb_all[subset][i]
            if subset == 'gen':
                seg = _read_seg(seg_dir_gen + '%s_%s.bmp' % (image_info['id_1'][i], image_info['id_2'][i]))
            else:
                seg = _read_seg(seg_dir + '%s.bmp' % image_info['id_%s'%subset][i])

            d_seg = [d_rgb*seg[...,j:(j+1)] for j in range(seg.shape[-1])]
            d_seg = np.concatenate(d_seg, axis=2)
            desc[subset].append(d_seg)
        desc[subset] = np.stack(desc[subset])

    data_dict_gt =  {
        'desc_1': desc['1'],
        'desc_2': desc['2'],
        'name': 'gt_seg-rgb'
    }
    data_dict_gen = {
        'desc_1': desc['1'],
        'desc_2': desc['gen'],
        'name': 'gen_seg-rgb'
    }

    scipy.io.matlab.savemat('temp/patch_matching/descriptor/desc_gt_seg-rgb.mat', data_dict_gt)
    scipy.io.matlab.savemat('temp/patch_matching/descriptor/desc_gen_seg-rgb.mat', data_dict_gen)

def create_descriptor_segment_guided_vgg():
    '''This function is deprecated. Segment guide is applied in expand_descriptor_by_seg.m'''
    model_id = 'PoseTransfer_7.5'
    image_info = io.load_json('temp/patch_matching/label/image_info.json')
    seg_dir = 'datasets/DF_Pose/Img/seg-lip_df/'
    seg_dir_gen = '/data2/ynli/Fashion/fashionHD/checkpoints/%s/test_seg/' % model_id
    desc_rgb = scipy.io.loadmat('temp/patch_matching/descriptor/desc_gt_rgb.mat')
    desc_rgb_gen = scipy.io.loadmat('temp/patch_matching/descriptor/desc_gen_rgb.mat')

    desc_rgb_all = {
        '1': desc_rgb['desc_1'],
        '2': desc_rgb['desc_2'],
        'gen': desc_rgb_gen['desc_2'],
    }

    desc = {}
    for subset in ['1', '2', 'gen']:
        desc[subset] = []
        for i in range(num_sample):
            d_rgb = desc_rgb_all[subset][i]
            if subset == 'gen':
                seg = _read_seg(seg_dir_gen + '%s_%s.bmp' % (image_info['id_1'][i], image_info['id_2'][i]))
            else:
                seg = _read_seg(seg_dir + '%s.bmp' % image_info['id_%s'%subset][i])

            d_seg = [d_rgb*seg[...,j:(j+1)] for j in range(seg.shape[-1])]
            d_seg = np.concatenate(d_seg, axis=2)
            desc[subset].append(d_seg)
        desc[subset] = np.stack(desc[subset])

    data_dict_gt =  {
        'desc_1': desc['1'],
        'desc_2': desc['2'],
        'name': 'gt_seg-rgb'
    }
    data_dict_gen = {
        'desc_1': desc['1'],
        'desc_2': desc['gen'],
        'name': 'gen_seg-rgb'
    }

    scipy.io.matlab.savemat('temp/patch_matching/descriptor/desc_gt_seg-rgb.mat', data_dict_gt)
    scipy.io.matlab.savemat('temp/patch_matching/descriptor/desc_gen_seg-rgb.mat', data_dict_gen)

def create_descriptor_inhomogeneous_seg():
    '''
    only used with segment guide
    '''
    tps = cv2.createThinPlateSplineShapeTransformer()
    image_info = io.load_json('temp/patch_matching/label/image_info.json')
    pose_label = io.load_data('datasets/DF_Pose/Label/pose_label.pkl')
   
    pose_np = np.array(pose_label.values())
    valid_rshoulder = pose_np[:,2,0]>=0
    mean_p_rshoulder = pose_np[valid_rshoulder,2,:].mean(axis=0)
    valid_lshoulder = pose_np[:,5,0]>=0
    mean_p_lshoulder = pose_np[valid_lshoulder,5,:].mean(axis=0)
    valid_rhip = pose_np[:,8,0]>=0
    mean_p_rhip = pose_np[valid_rhip,8,:].mean(axis=0)
    valid_lhip = pose_np[:,11,0]>=0
    mean_p_lhip = pose_np[valid_lhip,11,:].mean(axis=0)

    img_size = 256
    gx, gy = np.meshgrid(np.linspace(-1,1,img_size), np.linspace(-1,1,img_size), indexing='xy')
    grid_std = np.stack((gx,gy), axis=2)
    kp_std = np.stack([mean_p_rshoulder, mean_p_rhip, mean_p_lhip, mean_p_lshoulder]).reshape(1,-1,2).astype(np.float64)

    desc = {}
    for subset in ['1', '2', 'gen']:
        print(subset)
        desc[subset] = []
        for i in range(num_sample):
            if subset == '1':
                pose = np.array(pose_label[image_info['id_1'][i]])
            else:
                pose = np.array(pose_label[image_info['id_2'][i]])
            kp_tar = pose[[2,8,11,5],:].reshape(1,-1,2).astype(np.float64)
            kp_matches = []
            for j in range(kp_tar.shape[1]):
                if (kp_tar[0,j]>=0).all():
                    kp_matches.append(cv2.DMatch(j,j,0))
            if len(kp_matches) <=1:
                grid_tar = grid_std.copy()
            else:
                tps.estimateTransformation(kp_tar, kp_std, kp_matches)
                grid_tar = tps.warpImage(grid_std.copy())

            desc[subset].append(grid_tar)
        desc[subset] = np.stack(desc[subset])

    data_dict_gt =  {
        'desc_1': desc['1'],
        'desc_2': desc['2'],
        'name': 'gt_inhomoseg'
    }
    data_dict_gen = {
        'desc_1': desc['1'],
        'desc_2': desc['gen'],
        'name': 'gen_inhomoseg'
    }

    scipy.io.matlab.savemat('temp/patch_matching/descriptor/desc_gt_inhomoseg.mat', data_dict_gt)
    scipy.io.matlab.savemat('temp/patch_matching/descriptor/desc_gen_inhomoseg.mat', data_dict_gen)

def create_descriptor_inhomogeneous_seg_v2():

    alpha = 1.0

    image_info = io.load_json('temp/patch_matching/label/image_info.json')
    pose_label = io.load_data('datasets/DF_Pose/Label/pose_label.pkl')

    pose_np = np.array(pose_label.values())
    valid_index = (pose_np[:,[2,5,8,11],0]>=0).all(axis=1)
    pose_np = pose_np[valid_index, ...]
    mean_R = 0.5 * (np.linalg.norm(pose_np[:,2,:]-pose_np[:,8,:], axis=1).mean() + np.linalg.norm(pose_np[:,5,:]-pose_np[:,11,:], axis=1).mean())
    
    img_size = 256
    
    def _RBF(r, R, img_size):
        rx, ry = r
        gx, gy = np.meshgrid(range(img_size), range(img_size), indexing='xy')
        rbf = np.exp(-((gx-rx)**2 + (gy-ry)**2)/R**2)
        return rbf


    desc = {}
    kp_indices = [2,5,8,11,3,6]
    for subset in ['1', '2', 'gen']:
        print(subset)
        desc[subset] = []
        for i in range(num_sample):            
            if subset == '1':
                pose = np.array(pose_label[image_info['id_1'][i]])
            else:
                pose = np.array(pose_label[image_info['id_2'][i]])

            if (pose[[2,5,8,11],:] >=0).all():
                R = 0.5*(np.linalg.norm(pose[2,:]-pose[8,:]) + np.linalg.norm(pose[5,:]-pose[11,:]))
            else:
                R = mean_R
            m = np.zeros((img_size, img_size, len(kp_indices)))
            for i_kp, (x_kp, y_kp) in enumerate(pose[kp_indices,:]):
                valid = pose_label[image_info['id_1'][i]][i_kp][0] >= 0 and pose_label[image_info['id_2'][i]][i_kp][0] >= 0
                if valid:
                    m[..., i_kp] = _RBF(r=[x_kp, y_kp], R=R*alpha, img_size=img_size)
            desc[subset].append(m)
        desc[subset] = np.stack(desc[subset])

    data_dict_gt =  {
        'desc_1': desc['1'],
        'desc_2': desc['2'],
        'name': 'gt_inhomoseg-v2-1.0'
    }
    data_dict_gen = {
        'desc_1': desc['1'],
        'desc_2': desc['gen'],
        'name': 'gen_inhomoseg-v2-1.0'
    }

    scipy.io.matlab.savemat('temp/patch_matching/descriptor/desc_gt_inhomoseg-v2-1.0.mat', data_dict_gt)
    scipy.io.matlab.savemat('temp/patch_matching/descriptor/desc_gen_inhomoseg-v2-1.0.mat', data_dict_gen)




def create_descriptor_vunet():
    '''
    use variational unet feature as descriptor
    '''
    import torch
    from models.vunet_pose_transfer_model import VUnetPoseTransferModel
    from data.data_loader import CreateDataLoader
    from options.pose_transfer_options import TestPoseTransferOptions
    # load image info
    image_info = io.load_json('temp/patch_matching/label/image_info.json')
    # load model
    # opt = TestPoseTransferOptions().parse(ord_str = '--which_model_T vunet --id 7.5 --gpu_ids 0,1,2,3 --batch_size 16', save_to_file = False, display = False, set_gpu = True)
    opt = TestPoseTransferOptions().parse(ord_str = '--which_model_T vunet --id 7.9 --gpu_ids 0,1,2,3 --batch_size 16', save_to_file = False, display = False, set_gpu = True)
    train_opt = io.load_json(os.path.join('checkpoints', opt.id, 'train_opt.json'))
    for k, v in train_opt.iteritems():
        if k in opt and (k not in {'gpu_ids', 'is_train'}):
            setattr(opt, k, v)
    model = VUnetPoseTransferModel()
    model.initialize(opt)
    # create data set
    val_loader = CreateDataLoader(opt, split='test')
    id_list = [[sid_1, sid_2] for sid_1, sid_2 in zip(image_info['id_1'], image_info['id_2'])]
    val_loader.dataset.id_list = id_list

    # extract descriptor
    print('extracing descriptors ...')
    desc = {
        'img_1': [],
        'img_2': [],
        'feat1_1': [],
        'feat1_2': [],
        'feat2_1': [],
        'feat2_2': [],
    }
    for i, data in enumerate(tqdm.tqdm(val_loader)):
        model.set_input(data)
        appr_1 = model.get_appearance(model.opt.appearance_type, index='1')
        appr_2 = model.get_appearance(model.opt.appearance_type, index='2')
        pose_1 = model.get_pose(model.opt.pose_type, index='1')
        pose_2 = model.get_pose(model.opt.pose_type, index='2')
        # desc_1 (ref)
        output, ps, qs, ds = model.netT(appr_1, pose_1, pose_1, mode='transfer', output_feature=True)
        output = model.parse_output(output, model.opt.output_type)
        img = torch.nn.functional.tanh(output['image'])
        desc['img_1'].append(img.detach().cpu())
        desc['feat1_1'].append(ds[-1].detach().cpu())
        desc['feat2_1'].append(ds[-2].detach().cpu())
        # desc_2 (tar)
        output, ps, qs, ds = model.netT(appr_1, pose_1, pose_2, mode='transfer', output_feature=True)
        output = model.parse_output(output, model.opt.output_type)
        img = torch.nn.functional.tanh(output['image'])
        desc['img_2'].append(img.detach().cpu())
        desc['feat1_2'].append(ds[-1].detach().cpu())
        desc['feat2_2'].append(ds[-2].detach().cpu())
    
    for k, v in desc.iteritems():
        desc[k] = torch.cat(v).numpy().transpose(0,2,3,1)

    # save descriptor
    data_dict_img = {
        'desc_1': desc['img_1'],
        'desc_2': desc['img_2'],
        'name': 'gen_vunet_img'
    }
    data_dict_feat1 = {
        'desc_1': desc['feat1_1'],
        'desc_2': desc['feat1_2'],
        'name': 'gen_vunet_feat1'
    }
    data_dict_feat2 = {
        'desc_1': desc['feat2_1'],
        'desc_2': desc['feat2_2'],
        'name': 'gen_vunet_feat2'
    }

    scipy.io.matlab.savemat('temp/patch_matching/descriptor/desc_gen_vunet-7.9_img.mat', data_dict_img)
    scipy.io.matlab.savemat('temp/patch_matching/descriptor/desc_gen_vunet-7.9_feat1.mat', data_dict_feat1)
    scipy.io.matlab.savemat('temp/patch_matching/descriptor/desc_gen_vunet-7.9_feat2.mat', data_dict_feat2)

    # visualize desc_img
    vis_dir = 'temp/patch_matching/descriptor/vis_gen_vunet_img/'
    io.mkdir_if_missing(vis_dir)
    imgs_1 = (desc['img_1']*127.5 + 127.5).astype(np.uint8)
    imgs_2 = (desc['img_2']*127.5 + 127.5).astype(np.uint8)
    for i in range(imgs_1.shape[0]):
        imageio.imwrite(vis_dir+'%d_1.jpg'%i, imgs_1[i])
        imageio.imwrite(vis_dir+'%d_2.jpg'%i, imgs_2[i])




if __name__ == '__main__':
    ###########################
    # patchmatch functions
    ###########################
    create_image_info()
    # create_descriptor_seg()
    # create_descriptor_rgb()
    # create_descriptor_vgg()
    # create_descriptor_segment_guided_rgb()
    # create_descriptor_inhomogeneous_seg()

    # create_descriptor_vunet()
    # create_descriptor_inhomogeneous_seg_v2()